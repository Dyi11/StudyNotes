# StudyNotes

## Transformer：

网课：【保姆级教学】不愧是李宏毅老师！一口气transformer的自注意力机制、多头自注意力机制、编码器、解码器以及ViT、BERT、GPT等算法模型讲的明明白白！

## 深度学习代码：

李沐课程

网课：【2025版】李沐深度学习系列课程！涵盖CNN、RNN、LSTM、GAN、DQN、transformer、自编码器和注意力机制等神经网络核心知识点

代码：limu文件夹

## 深度学习理论基础：

鱼书

网课：整整150集！计算机博士竟然用视频的方式把《深度学习入门》讲解的如此通俗易懂！草履虫都学的会！（机器学习/计算机视觉/神经网络）

## 论文网站：

**CV三大顶会**

  1. CVPR，一年一次，https://openaccess.thecvf.com/CVPR2022 （2022）
  2. ICCV，两年一次，https://openaccess.thecvf.com/ICCV2021 （2021）
  3. ECCV，两年一次，只能在成刊后能见到原文（如果作者没有放在arxiv），https://link.springer.com/book/10.1007/978-3-030-58452-8 ，（2020年）
     
**ML三大顶会**

  1. ICML，每年一次，https://icml.cc/Conferences/2022/Schedule?type=Poster，（2022）。或者http://proceedings.mlr.press/，里边有ICML历年集合
  2. 2. ICLR，每年一次的较新会议，https://openreview.net/group?id=ICLR.cc/2022/Conference，（2022）
  3. 3. NeurIPS，每年一次，推荐大家可以直接在这个网站快速找到每一年的，https://papers.nips.cc/
      
**两个有争议的会**

  1. AAAI，每年一次，https://aaai.org/Conferences/AAAI-21/wp-content/uploads/2020/12/AAAI-21_Accepted-Paper-List.Main_.Technical.Track_.pdf，（2021），是一个pdf文件，里边都是文章的title
  2. 2. IJCAI，一年一次，https://www.ijcai.org/past_proceedings，这个网站收录了历届的paper list
     
**Arxiv开源**

  https://arxiv.org/
