{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPFPJrDTM9Em7Abpt/zOgj/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":3,"metadata":{"id":"rai_Ohr0xXlE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1760621576793,"user_tz":-480,"elapsed":86,"user":{"displayName":"Yi Ding","userId":"00481053372005627191"}},"outputId":"7b4f07ea-2a8c-449b-a46f-d580238b2f94"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0., 1., 2., 3.])"]},"metadata":{},"execution_count":3}],"source":["import torch\n","x = torch.arange(4.0)\n","x"]},{"cell_type":"code","source":["x.requires_grad_(True)  #声明需要存梯度。计算y关于x的梯度之前，需要一个地方存梯度\n","x.grad # 默认是None\n","y = 2 * torch.dot(x,x)\n","y"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-PONcmCBNv7N","executionInfo":{"status":"ok","timestamp":1760621629015,"user_tz":-480,"elapsed":31,"user":{"displayName":"Yi Ding","userId":"00481053372005627191"}},"outputId":"46b18b7c-6089-467a-f326-3f059c372972"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(28., grad_fn=<MulBackward0>)"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["调用反向传播函数，自动计算y关于x每个分量的梯度"],"metadata":{"id":"GsHIS2PYO6c7"}},{"cell_type":"code","source":["y.backward()\n","x.grad # 4x1,4x2,4x3,4x4"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nL2dedttOs0q","executionInfo":{"status":"ok","timestamp":1760621690329,"user_tz":-480,"elapsed":11,"user":{"displayName":"Yi Ding","userId":"00481053372005627191"}},"outputId":"f903aec2-9e63-4656-adb6-190b3dd59d3f"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([ 0.,  4.,  8., 12.])"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["x.grad == 4 * x"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_5trwZm8PTha","executionInfo":{"status":"ok","timestamp":1760621854605,"user_tz":-480,"elapsed":16,"user":{"displayName":"Yi Ding","userId":"00481053372005627191"}},"outputId":"b747d66b-3a10-43a0-cf4c-90b0f28e8e2e"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([True, True, True, True])"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["# 默认情况下，pytorch会累计梯度\n","x.grad.zero_() #梯度清零\n","y = x.sum()\n","y.backward()\n","x.grad"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xRItJ-QEPck8","executionInfo":{"status":"ok","timestamp":1760621962500,"user_tz":-480,"elapsed":17,"user":{"displayName":"Yi Ding","userId":"00481053372005627191"}},"outputId":"672878aa-5b95-404d-ae80-07484be7fe2b"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([1., 1., 1., 1.])"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","source":["深度学习中，我们的目的不是计算微分矩阵，而是每个批次中每个样本单独计算的偏导数之和"],"metadata":{"id":"2jlSVdxPP3Ot"}},{"cell_type":"code","source":["x.grad.zero_()\n","y = x * x\n","# 大部分情况是对标量求导，而非向量\n","y.sum().backward()\n","x.grad"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yilwKRY7PzOW","executionInfo":{"status":"ok","timestamp":1760622129814,"user_tz":-480,"elapsed":53,"user":{"displayName":"Yi Ding","userId":"00481053372005627191"}},"outputId":"bbdde9cc-7edc-4416-b288-e024954bfa64"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0., 2., 4., 6.])"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["x.grad.zero_()\n","y = x * x\n","# detach()是张量的一个方法，用于将张量从计算图中分离出来，使其不再再参与梯度计算，也不会保留与其他张量的梯度依赖关系\n","u = y.detach() # u从计算图中分离，对u操作不会影响梯度，u这里变成了常数\n","z= u * x\n","z.sum().backward()\n","x.grad == u"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"60u7Rn_iQrVd","executionInfo":{"status":"ok","timestamp":1760622564151,"user_tz":-480,"elapsed":44,"user":{"displayName":"Yi Ding","userId":"00481053372005627191"}},"outputId":"c539e6dd-5a02-4dde-fc0a-6887063fb34b"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([True, True, True, True])"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["x.grad.zero_()\n","y.sum().backward()\n","x.grad == 2 * x"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JoF2OvEKSG0L","executionInfo":{"status":"ok","timestamp":1760622798845,"user_tz":-480,"elapsed":8,"user":{"displayName":"Yi Ding","userId":"00481053372005627191"}},"outputId":"41d7360a-70d7-41c1-eac5-ef74980a7725"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([True, True, True, True])"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["def f(a):\n","  b = a * 2\n","  while b.norm() < 1000:\n","    b = b * 2\n","  if b.sum() > 0:\n","    c = b\n","  else:\n","    c = 100 * b\n","  return c\n","\n","a = torch.randn(size=(),requires_grad=True)\n","d = f(a)\n","d.backward()\n","\n","a.grad == d/a #通过函数，变量梯度仍能计算"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7x0URq92THta","executionInfo":{"status":"ok","timestamp":1760623036079,"user_tz":-480,"elapsed":21,"user":{"displayName":"Yi Ding","userId":"00481053372005627191"}},"outputId":"aacea0db-96ef-45c7-a6d5-bf3a9a5e8dfb"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(True)"]},"metadata":{},"execution_count":15}]}]}