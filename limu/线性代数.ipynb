{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMap1Hxw0qXnEspJGA3Uoii"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HlEClD7L8Juq","executionInfo":{"status":"ok","timestamp":1760610432695,"user_tz":-480,"elapsed":6473,"user":{"displayName":"Yi Ding","userId":"00481053372005627191"}},"outputId":"94b928f6-f321-446e-e4a0-1c016f9867e8"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0,  1,  2,  3],\n","        [ 4,  5,  6,  7],\n","        [ 8,  9, 10, 11],\n","        [12, 13, 14, 15],\n","        [16, 17, 18, 19]])"]},"metadata":{},"execution_count":1}],"source":["import torch\n","\n","# 创建5x4的矩阵\n","A = torch.arange(20).reshape((5,4))\n","A"]},{"cell_type":"code","source":["A.T # 转置"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ts11keEw-gr8","executionInfo":{"status":"ok","timestamp":1760610432711,"user_tz":-480,"elapsed":11,"user":{"displayName":"Yi Ding","userId":"00481053372005627191"}},"outputId":"c35e56c7-3b23-4e12-fee5-481feb379701"},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0,  4,  8, 12, 16],\n","        [ 1,  5,  9, 13, 17],\n","        [ 2,  6, 10, 14, 18],\n","        [ 3,  7, 11, 15, 19]])"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["B = torch.tensor([[1,2,3],[2,0,4],[3,4,5]])\n","B"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xkdyMAN7-msd","executionInfo":{"status":"ok","timestamp":1760610432733,"user_tz":-480,"elapsed":18,"user":{"displayName":"Yi Ding","userId":"00481053372005627191"}},"outputId":"4655bfa7-8123-4135-aeee-178939800329"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1, 2, 3],\n","        [2, 0, 4],\n","        [3, 4, 5]])"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["B == B.T #对称矩阵的转置前后相等"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vrx5rXtc-7v8","executionInfo":{"status":"ok","timestamp":1760610432745,"user_tz":-480,"elapsed":9,"user":{"displayName":"Yi Ding","userId":"00481053372005627191"}},"outputId":"7e1ac880-a768-457a-b08c-5d61c61f881c"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[True, True, True],\n","        [True, True, True],\n","        [True, True, True]])"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["A = torch.arange(20,dtype=torch.float32).reshape((5,4))\n","B = A.clone() #分配新内存，把一个A的副本分配给B\n","A, A+B"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cv8-I4L7_D1Y","executionInfo":{"status":"ok","timestamp":1760610432761,"user_tz":-480,"elapsed":14,"user":{"displayName":"Yi Ding","userId":"00481053372005627191"}},"outputId":"a9647105-98b6-4232-a4c8-ed84a21a6a79"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[ 0.,  1.,  2.,  3.],\n","         [ 4.,  5.,  6.,  7.],\n","         [ 8.,  9., 10., 11.],\n","         [12., 13., 14., 15.],\n","         [16., 17., 18., 19.]]),\n"," tensor([[ 0.,  2.,  4.,  6.],\n","         [ 8., 10., 12., 14.],\n","         [16., 18., 20., 22.],\n","         [24., 26., 28., 30.],\n","         [32., 34., 36., 38.]]))"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["A * B # 矩阵按元素乘法（哈达玛积），数学符号是圈里面有个点"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gO_iK9zNAf2Z","executionInfo":{"status":"ok","timestamp":1760610432778,"user_tz":-480,"elapsed":12,"user":{"displayName":"Yi Ding","userId":"00481053372005627191"}},"outputId":"3967d089-f597-4435-f3e6-6f79079d7fe9"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[  0.,   1.,   4.,   9.],\n","        [ 16.,  25.,  36.,  49.],\n","        [ 64.,  81., 100., 121.],\n","        [144., 169., 196., 225.],\n","        [256., 289., 324., 361.]])"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["a = 2\n","X = torch.arange(24).reshape(2,3,4)\n","X, a+X, a*X#数字和矩阵的加法跟哈达玛积也是按照元素算的，类似把一个数，当成跟矩阵同维度且各元素都是这个数的矩阵"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zh6zfmhwA05C","executionInfo":{"status":"ok","timestamp":1760610432810,"user_tz":-480,"elapsed":29,"user":{"displayName":"Yi Ding","userId":"00481053372005627191"}},"outputId":"5d35d128-c2af-4772-f13e-1abc0397e4c9"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[[ 0,  1,  2,  3],\n","          [ 4,  5,  6,  7],\n","          [ 8,  9, 10, 11]],\n"," \n","         [[12, 13, 14, 15],\n","          [16, 17, 18, 19],\n","          [20, 21, 22, 23]]]),\n"," tensor([[[ 2,  3,  4,  5],\n","          [ 6,  7,  8,  9],\n","          [10, 11, 12, 13]],\n"," \n","         [[14, 15, 16, 17],\n","          [18, 19, 20, 21],\n","          [22, 23, 24, 25]]]),\n"," tensor([[[ 0,  2,  4,  6],\n","          [ 8, 10, 12, 14],\n","          [16, 18, 20, 22]],\n"," \n","         [[24, 26, 28, 30],\n","          [32, 34, 36, 38],\n","          [40, 42, 44, 46]]]))"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["指定求和汇总张量的轴"],"metadata":{"id":"HEz6SKPuCYyL"}},{"cell_type":"code","source":["A = torch.arange(20*2).reshape(2,5,4)\n","A, A.shape, A.sum()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5BUtIb1NCx3U","executionInfo":{"status":"ok","timestamp":1760610432938,"user_tz":-480,"elapsed":122,"user":{"displayName":"Yi Ding","userId":"00481053372005627191"}},"outputId":"b288ecab-1bc4-406f-a9ff-a1b9b8837716"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[[ 0,  1,  2,  3],\n","          [ 4,  5,  6,  7],\n","          [ 8,  9, 10, 11],\n","          [12, 13, 14, 15],\n","          [16, 17, 18, 19]],\n"," \n","         [[20, 21, 22, 23],\n","          [24, 25, 26, 27],\n","          [28, 29, 30, 31],\n","          [32, 33, 34, 35],\n","          [36, 37, 38, 39]]]),\n"," torch.Size([2, 5, 4]),\n"," tensor(780))"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["# A.sum()不指定任何维度，会对数组或张量A中的所有元素进行求和，返回一个标量（单一数值）\n","# 数组的维度索引从0开始，依次对应“最外层维度”到“最内层维度”，对应在（）里的参数，就是从左往右\n","A_sum_axis0 = A.sum(axis=0)# 指定axis=0，表示沿着第0维进行求和，返回一个降维后的数组/张量，加完了就没这一维了\n","A_sum_axis0, A_sum_axis0.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vg9HOXe3B55p","executionInfo":{"status":"ok","timestamp":1760610432972,"user_tz":-480,"elapsed":31,"user":{"displayName":"Yi Ding","userId":"00481053372005627191"}},"outputId":"41f03aea-4a6e-48e2-c2b2-47d563cf3447"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[20, 22, 24, 26],\n","         [28, 30, 32, 34],\n","         [36, 38, 40, 42],\n","         [44, 46, 48, 50],\n","         [52, 54, 56, 58]]),\n"," torch.Size([5, 4]))"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["A_sum_axis1 = A.sum(axis=1)\n","A_sum_axis1, A_sum_axis1.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PLP76SWfCyZL","executionInfo":{"status":"ok","timestamp":1760610432975,"user_tz":-480,"elapsed":25,"user":{"displayName":"Yi Ding","userId":"00481053372005627191"}},"outputId":"85282fc0-9167-4534-fa8e-49e0a85f62ad"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[ 40,  45,  50,  55],\n","         [140, 145, 150, 155]]),\n"," torch.Size([2, 4]))"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["A.sum(axis=[0,1]) # 和A.sum()相同"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AP2uiaE6DIZ3","executionInfo":{"status":"ok","timestamp":1760610432976,"user_tz":-480,"elapsed":16,"user":{"displayName":"Yi Ding","userId":"00481053372005627191"}},"outputId":"399ed0bc-1551-4b04-d174-d0194d27a405"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([180, 190, 200, 210])"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["A.sum(axis=[0,1]).shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RvmiaeE-C42N","executionInfo":{"status":"ok","timestamp":1760610432985,"user_tz":-480,"elapsed":9,"user":{"displayName":"Yi Ding","userId":"00481053372005627191"}},"outputId":"309bc641-f773-4699-f0b6-347092ab58c8"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([4])"]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","source":["求均值"],"metadata":{"id":"S2GU6P4jHHb9"}},{"cell_type":"code","source":["A = A.float()#整数型不能求mean，转成浮点才行\n","A.mean(), A.sum()/A.numel()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4ZSlNFouHM2D","executionInfo":{"status":"ok","timestamp":1760610433117,"user_tz":-480,"elapsed":130,"user":{"displayName":"Yi Ding","userId":"00481053372005627191"}},"outputId":"ee464ee0-e02e-4eaf-e1ba-ce15d535c055"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor(19.5000), tensor(19.5000))"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["A.mean(axis=0), A.sum(axis=0)/A.shape[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g7R93gB7Ho--","executionInfo":{"status":"ok","timestamp":1760610433126,"user_tz":-480,"elapsed":33,"user":{"displayName":"Yi Ding","userId":"00481053372005627191"}},"outputId":"97c2387e-f554-4c9a-c56a-83a4d35d8b0a"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[10., 11., 12., 13.],\n","         [14., 15., 16., 17.],\n","         [18., 19., 20., 21.],\n","         [22., 23., 24., 25.],\n","         [26., 27., 28., 29.]]),\n"," tensor([[10., 11., 12., 13.],\n","         [14., 15., 16., 17.],\n","         [18., 19., 20., 21.],\n","         [22., 23., 24., 25.],\n","         [26., 27., 28., 29.]]))"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["sum_A = A.sum(axis=1,keepdims=True)\n","''' keepdims=True：保持求和后的维度数量不变（保留原维度结构）。\n","  若不设置（默认keepdims=False），求和后会删除该维度\n","  tensor([[ 40,  45,  50,  55],\n","      [140, 145, 150, 155]])\n","  设置为True则会保留该维度，仅将其大小变为1\n","'''\n","sum_A"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aKZYTZ-XJ44c","executionInfo":{"status":"ok","timestamp":1760610433127,"user_tz":-480,"elapsed":24,"user":{"displayName":"Yi Ding","userId":"00481053372005627191"}},"outputId":"4c41ff74-fbbd-4694-afe9-8fc8928d3de2"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[ 40.,  45.,  50.,  55.]],\n","\n","        [[140., 145., 150., 155.]]])"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["A / sum_A # 通过广播机制，让A和sum_A两个形状不匹配的矩阵能做除法，本质是在做归一化，便于后续分析或计算"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nN89rPWLKDVD","executionInfo":{"status":"ok","timestamp":1760610433129,"user_tz":-480,"elapsed":16,"user":{"displayName":"Yi Ding","userId":"00481053372005627191"}},"outputId":"b3c5019c-d2a3-43fb-f4ed-6dc92607c5c0"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[0.0000, 0.0222, 0.0400, 0.0545],\n","         [0.1000, 0.1111, 0.1200, 0.1273],\n","         [0.2000, 0.2000, 0.2000, 0.2000],\n","         [0.3000, 0.2889, 0.2800, 0.2727],\n","         [0.4000, 0.3778, 0.3600, 0.3455]],\n","\n","        [[0.1429, 0.1448, 0.1467, 0.1484],\n","         [0.1714, 0.1724, 0.1733, 0.1742],\n","         [0.2000, 0.2000, 0.2000, 0.2000],\n","         [0.2286, 0.2276, 0.2267, 0.2258],\n","         [0.2571, 0.2552, 0.2533, 0.2516]]])"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["# A.cumsum(axis=0)是计算数组或张量A沿着第0维的累积和，即从起始位置开始，依次累加当前元素与前面所有元素的总和。\n","C = torch.tensor([[1, 2, 3, 4],\n","          [5, 6, 7, 8],\n","          [9, 10, 11, 12]])\n","\"\"\"\n","  tensor([[ 1,  2,  3,  4],       # 第0行：自身（无前置元素）\n","        [ 6,  8, 10, 12],      # 第1行：第0行 + 第1行（1+5=6, 2+6=8, ...）\n","        [15, 18, 21, 24]])     # 第2行：第0行 + 第1行 + 第2行（6+9=15, 8+10=18, ...）\n","\"\"\"\n","A.cumsum(axis=0),C.cumsum(axis=0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RNIBsi8aKJCg","executionInfo":{"status":"ok","timestamp":1760610433137,"user_tz":-480,"elapsed":11,"user":{"displayName":"Yi Ding","userId":"00481053372005627191"}},"outputId":"4c979b02-1267-47c4-a4d5-a2d014f6c01d"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[[ 0.,  1.,  2.,  3.],\n","          [ 4.,  5.,  6.,  7.],\n","          [ 8.,  9., 10., 11.],\n","          [12., 13., 14., 15.],\n","          [16., 17., 18., 19.]],\n"," \n","         [[20., 22., 24., 26.],\n","          [28., 30., 32., 34.],\n","          [36., 38., 40., 42.],\n","          [44., 46., 48., 50.],\n","          [52., 54., 56., 58.]]]),\n"," tensor([[ 1,  2,  3,  4],\n","         [ 6,  8, 10, 12],\n","         [15, 18, 21, 24]]))"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["x = torch.tensor([1.0,2,3,4])\n","y = torch.ones(4,dtype=torch.float32)\n","#dot点积是相同位置的按元素乘积的和，是个标量\n","x,y,torch.dot(x,y),x*y"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jR89vfyJKOrV","executionInfo":{"status":"ok","timestamp":1760610433145,"user_tz":-480,"elapsed":7,"user":{"displayName":"Yi Ding","userId":"00481053372005627191"}},"outputId":"907ff3bc-af58-4d49-f7d4-cf984d37b2a4"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([1., 2., 3., 4.]),\n"," tensor([1., 1., 1., 1.]),\n"," tensor(10.),\n"," tensor([1., 2., 3., 4.]))"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["torch.dot(x,y) == torch.sum(x*y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c7t_eCtRKh4J","executionInfo":{"status":"ok","timestamp":1760610433155,"user_tz":-480,"elapsed":8,"user":{"displayName":"Yi Ding","userId":"00481053372005627191"}},"outputId":"22d2ed91-af3b-4bf6-c65d-8090eec9aa90"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(True)"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["# 创建一个2x3的矩阵 (2行3列)\n","A = torch.tensor([\n","    [1.0, 2.0, 3.0],\n","    [4.0, 5.0, 6.0]\n","])\n","\n","# 创建一个长度为3的向量 (与矩阵的列数匹配)\n","x = torch.tensor([7.0, 8.0, 9.0])\n","\n","# 检查维度\n","print(\"A的形状:\", A.shape)  # 应输出 torch.Size([2, 3])\n","print(\"x的形状:\", x.shape)  # 应输出 torch.Size([3])\n","\n","# 执行矩阵与向量的乘法Ax\n","result = torch.mv(A, x)\n","print(\"结果:\", result)      # 应输出 tensor([ 50., 122.]) 1*7+2*8+3*9=50\n","print(\"结果形状:\", result.shape)  # 应输出 torch.Size([2])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3E19C8gAPHtC","executionInfo":{"status":"ok","timestamp":1760610433165,"user_tz":-480,"elapsed":9,"user":{"displayName":"Yi Ding","userId":"00481053372005627191"}},"outputId":"8d794e86-f7a1-45a4-8eb0-f50a03874e6a"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["A的形状: torch.Size([2, 3])\n","x的形状: torch.Size([3])\n","结果: tensor([ 50., 122.])\n","结果形状: torch.Size([2])\n"]}]},{"cell_type":"markdown","source":["矩阵与向量乘法（torch.mv(A, x)）的元素通用求解公式如下：\n","\n","设：矩阵 A 为 n×m 维（n 行，m 列），元素表示为 A[i][j]（第 i 行第 j 列）向量 x 为 m 维（长度为 m），元素表示为 x[j]（第 j 个元素）结果向量 result 为 n 维，元素表示为 result[i]（第 i 个元素）则结果向量中第 i 个元素的计算公式为：result[i] = A[i][j]*[j] （j从0取到m-1，求得的乘积之和为result[i]，累加符号打不出）\n","\n","以之前的示例为例：\n","result[0] = A[0][0]×x[0] + A[0][1]×x[1] + A[0][2]×x[2]\n","result[1] = A[1][0]×x[0] + A[1][1]×x[1] + A[1][2]×x[2]"],"metadata":{"id":"DRqdJNDPkvg1"}},{"cell_type":"code","source":["A = torch.tensor([[1.0, 2.0, 3.0],\n","          [4.0, 5.0, 6.0]])\n","B = torch.ones(3,4)\n","torch.mm(A,B)#矩阵乘法"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mA15UGeOlapN","executionInfo":{"status":"ok","timestamp":1760610982516,"user_tz":-480,"elapsed":14,"user":{"displayName":"Yi Ding","userId":"00481053372005627191"}},"outputId":"f9fff9ea-d86b-4d2b-ffe3-f3228be62b4f"},"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 6.,  6.,  6.,  6.],\n","        [15., 15., 15., 15.]])"]},"metadata":{},"execution_count":22}]},{"cell_type":"markdown","source":["矩阵乘法(平时正常的非前面说的按元素的）AB，可以看作简单的执行多次矩阵和向量乘法，并将结果拼接在一起"],"metadata":{"id":"DTfcrZaXl8Gm"}},{"cell_type":"code","source":["u = torch.tensor([3.0,-4.0])\n","torch.norm(u) # 求她的L2范数，即向量元素的平方和的平方根"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qNgoAh9SmSJE","executionInfo":{"status":"ok","timestamp":1760611185813,"user_tz":-480,"elapsed":12,"user":{"displayName":"Yi Ding","userId":"00481053372005627191"}},"outputId":"8c8e5c50-b109-4401-8d06-6693ded7a2df"},"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(5.)"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["torch.abs(u).sum() # 求L1范数，表示向量元素的绝对值之和"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oaGxIR3nmsai","executionInfo":{"status":"ok","timestamp":1760611313679,"user_tz":-480,"elapsed":9,"user":{"displayName":"Yi Ding","userId":"00481053372005627191"}},"outputId":"ce42c6b5-6e87-4711-a611-3e370c81a961"},"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(7.)"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["torch.norm(torch.ones((4,9))) # 矩阵的Frobenius范数，是矩阵元素的平方和的平方根"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jpagEhG2m2_c","executionInfo":{"status":"ok","timestamp":1760611361207,"user_tz":-480,"elapsed":32,"user":{"displayName":"Yi Ding","userId":"00481053372005627191"}},"outputId":"5d96ba48-a2ca-42b0-8acd-1f2902e85ee8"},"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(6.)"]},"metadata":{},"execution_count":31}]}]}